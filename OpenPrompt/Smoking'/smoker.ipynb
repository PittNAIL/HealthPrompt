{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bgm_jBuEbJb-"
   },
   "outputs": [],
   "source": [
    "!pip install -q openprompt==0.1.1 \\\n",
    "'torch>=1.9.0' \\\n",
    "'transformers>=4.10.0' \\\n",
    "sentencepiece==0.1.96 \\\n",
    "'scikit-learn>=0.24.2' \\\n",
    "'tqdm>=4.62.2' \\\n",
    "tensorboardX \\\n",
    "nltk \\\n",
    "yacs \\\n",
    "dill \\\n",
    "datasets \\\n",
    "rouge==1.0.0 \\\n",
    "scipy==1.4.1 \\\n",
    "fugashi \\\n",
    "ipadic \\\n",
    "unidic-lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "tree = ET.parse('./smokers_surrogate_train_all_version2.xml')\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RECORD {'ID': '641'}\n",
      "RECORD {'ID': '643'}\n",
      "RECORD {'ID': '681'}\n",
      "RECORD {'ID': '704'}\n",
      "RECORD {'ID': '757'}\n",
      "RECORD {'ID': '786'}\n",
      "RECORD {'ID': '872'}\n",
      "RECORD {'ID': '874'}\n",
      "RECORD {'ID': '535'}\n",
      "RECORD {'ID': '540'}\n"
     ]
    }
   ],
   "source": [
    "root.attrib\n",
    "root.tag\n",
    "counter=0\n",
    "for child in root:\n",
    "    if counter == 10:\n",
    "        break\n",
    "    print(child.tag, child.attrib)\n",
    "    counter +=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT\n",
      "RECORD\n",
      "SMOKING\n",
      "TEXT\n",
      "RECORD\n",
      "SMOKING\n",
      "TEXT\n",
      "RECORD\n",
      "SMOKING\n",
      "TEXT\n"
     ]
    }
   ],
   "source": [
    "[elem.tag for elem in root.iter()]\n",
    "\n",
    "counter=0\n",
    "for elem in root.iter():\n",
    "    if counter==10:\n",
    "        break\n",
    "    print(elem.tag)\n",
    "    counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT SMOKER\n",
      "CURRENT SMOKER\n",
      "CURRENT SMOKER\n",
      "CURRENT SMOKER\n",
      "CURRENT SMOKER\n",
      "CURRENT SMOKER\n",
      "CURRENT SMOKER\n",
      "CURRENT SMOKER\n",
      "CURRENT SMOKER\n",
      "CURRENT SMOKER\n"
     ]
    }
   ],
   "source": [
    "counter=0\n",
    "for smoking in root.iter('SMOKING'):\n",
    "    if counter==10:\n",
    "        break\n",
    "    print(smoking.attrib.get('STATUS'))\n",
    "    counter +=1\n",
    "    \n",
    "# for movie in root.iter('SMOKING'):\n",
    "#     print(movie.attrib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "977146916\n",
      "HLGMC\n",
      "2878891\n",
      "022690\n",
      "01/27/1997 12:00:00 AM\n",
      "CARCINOMA OF THE COLON .\n",
      "Unsigned\n",
      "DIS\n",
      "Report Status :\n",
      "Unsigned\n",
      "Please do not go above this box important format codes are contained .\n",
      "DISCHARGE SUMMARY\n",
      "ARF32 FA\n",
      "DISCHARGE SUMMARY NAME :\n",
      "GIRRESNET , DIEDREO A\n",
      "UNIT NUMBER :\n",
      "075-71-01\n",
      "ADMISSION DATE :\n",
      "01/27/1997\n",
      "DISCHARGE DATE :\n",
      "01/31/1997\n",
      "PRINCIPAL DIAGNOSIS :\n",
      "Carcinoma of the colon .\n",
      "ASSOCIATED DIAGNOSIS :\n",
      "Urinary tract infection , and cirrhosis of the liver .\n",
      "HISTORY OF PRESENT ILLNESS :\n",
      "The patient is an 80-year-old male , who had a history of colon cancer in the past , resected approximately ten years prior to admission , history of heavy alcohol use , who presented with a two week history of poor PO intake , weight loss , and was noted to have acute on chronic Hepatitis by chemistries and question of pyelonephritis .\n",
      "He lived alone but was driven to the hospital by his son because of reported worsening and general care and deconditioning .\n",
      "Emergency Department course ; he was evaluated in the emergency room , found to be severely cachectic and jaundiced .\n",
      "He was given a liter of normal saline , along with thiamine , folate .\n",
      "An abdominal ultrasound was performed showing no stones .\n",
      "Chest x-ray revealed clear lungs and then he was admitted to Team C for management .\n",
      "PAST MEDICAL HISTORY :\n",
      "Cancer , ten years prior to admission , status post resection .\n",
      "MEDICATIONS ON ADMISSION :\n",
      "Folic acid .\n",
      "ALLERGIES :\n",
      "None .\n",
      "FAMILY HISTORY :\n",
      "Not obtained .\n",
      "SOCIAL HISTORY :\n",
      "Lives in Merca .\n",
      "Drinks ginger brandy to excess , pipe and cigar smoker for many years .\n",
      "PHYSICAL EXAMINATION :\n",
      "In general was a cachectic , jaundiced man .\n",
      "bloodpressure :\n",
      "124/60 , 97.4 , 84 , 22 for vital signs .\n",
      "head , eyes , ears , nose and throat :\n",
      "notable for abscess ulcers on the lower gums .\n",
      "He was edentulous .\n",
      "Neck was supple , lungs were clear except for some scattered mild crackles .\n",
      "Cardiac :\n",
      "tachycardic with a II / VI systolic ejection murmur .\n",
      "Belly was tender in the right upper quadrant .\n",
      "Liver edge , thickened abdominal wall was palpable .\n",
      "No inguinal nodes .\n",
      "Rectal was guaiac negative .\n",
      "On mental status exam , he was somnolent but arousable .\n",
      "Oriented to name , year , and hospital .\n",
      "Skin was jaundiced .\n",
      "LABORATORY DATA :\n",
      "Notable for a BUN and creatinine 14 and 1.8 , phosphorous of .5 , magnesium 1.2 , albumin 2.1 .\n",
      "elevated liver function tests , bilirubin of 14 direct , 17 total .\n",
      "uric acid 11.4 , alkaline phosphatase 173 , serum glutamic oxaloacetic transaminase 309 , amylase 388 .\n",
      "His urinalysis showed 10-20 granular casts and 10-20 white blood cells , 3-5 red blood cells , 5-10 whites , 3-5 white blood cells cast .\n",
      "The white blood cell was 8.5 , hematocrit 34 .\n",
      "platelet count 74 .\n",
      "5% bands on differential .\n",
      "prothrombin time 14.9 , partial thromboplastin time 35 .\n",
      "HOSPITAL COURSE AND TREATMENT :\n",
      "The patient was admitted to the Staviewordna University Of Medical Center .\n",
      "His mental status proceeded to decline as he became more sleepy and less arousable and confused .\n",
      "His Hepatitis worsened , liver failure progressed with his coagulopathy worsening .\n",
      "His renal status also decreased with a drop in urine output , became more shortness of breath as he developed some pulmonary edema .\n",
      "A head computerized tomography scan was planned to evaluate his change in mental status , but after an extensive discussion with the son , who felt that he and other family members wanted to maximize the patient 's comforts and avoid heroic measures in the event of further deterioration , plans were made to make the patient as comfortable as possible .\n",
      "He was continued on antibiotics , and oxygen , and morphine , and small amounts of Dopamine , and at 4 AM on January 31 , was pronounced dead .\n",
      "_________________________ AJO C. CUCHKOTE , M.D.\n",
      "TR :\n",
      "tfv\n",
      "DD :\n",
      "09/08/1997\n",
      "TD :\n",
      "10/13/1997 3:47\n",
      "Pcc :\n",
      "AZEL USANNE WALL , M.D.\n",
      "[ report_end ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for text in root.iter('TEXT'):\n",
    "#     print(text.text)\n",
    "    \n",
    "counter=0\n",
    "for text in root.iter('TEXT'):\n",
    "    if counter==1:\n",
    "        break\n",
    "    print(text.text)\n",
    "    counter +=1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter=0\n",
    "for text in root.findall(\"./SMOKING/[@STATUS='CURRENT SMOKER']\"):\n",
    "    if counter==10:\n",
    "        break\n",
    "    print(text.attrib)\n",
    "    print(counter)\n",
    "    counter +=1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc=xee.fromstring('./smokers_surrogate_train_all_version2.xml')\n",
    "\n",
    "for tag in root.findall('SMOKING'):\n",
    "    if tag.attrib['STATUS']!='CURRENT SMOKER':\n",
    "#         root.remove(tag)\n",
    "        print(tag)\n",
    "        \n",
    "# print(ET.tostring(root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "641\n",
      "CURRENT SMOKER\n",
      "0\n",
      "643\n",
      "CURRENT SMOKER\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# node=root\n",
    "# if node.tag == \"SMOKING\":\n",
    "#         status = node.attrib.get(\"STATUS\")\n",
    "#         print(status)\n",
    "#         if status is not None:\n",
    "#             print(node.attrib.get(\"TEXT\"))\n",
    "import xml.etree.ElementTree as ET\n",
    "tree = ET.parse('./smokers_surrogate_train_all_version2.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "text_list=[]\n",
    "counter =0             \n",
    "for record in root.iter('RECORD'):\n",
    "    if counter == 2:\n",
    "        break\n",
    "    print(record.attrib.get('ID'))\n",
    "    smoking = record.find('SMOKING')\n",
    "    print(smoking.attrib.get('STATUS'))\n",
    "    if smoking.attrib.get('STATUS')==\"CURRENT SMOKER\":\n",
    "        text=record.find('TEXT')\n",
    "        text_list.append(text)\n",
    "        print(counter)\n",
    "    counter +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "tree = ET.parse('./smokers_surrogate_train_all_version2.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "text_list=[]\n",
    "label_list=[]\n",
    "counter =0             \n",
    "for record in root.iter('RECORD'):\n",
    "#     if counter:\n",
    "#         break\n",
    "#     print(record.attrib.get('ID'))\n",
    "    smoking = record.find('SMOKING')\n",
    "    label_list.append(smoking.attrib.get('STATUS'))\n",
    "#     print(smoking.attrib.get('STATUS'))\n",
    "    text=record.find('TEXT')\n",
    "    text_list.append(text)\n",
    "#     print(text_list.__len__())\n",
    "#     print(counter)\n",
    "    counter +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398\n",
      "398\n"
     ]
    }
   ],
   "source": [
    "print(text_list.__len__())\n",
    "print(label_list.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CURRENT SMOKER',\n",
       " 'CURRENT SMOKER',\n",
       " 'CURRENT SMOKER',\n",
       " 'CURRENT SMOKER',\n",
       " 'CURRENT SMOKER',\n",
       " 'CURRENT SMOKER',\n",
       " 'CURRENT SMOKER',\n",
       " 'CURRENT SMOKER',\n",
       " 'CURRENT SMOKER',\n",
       " 'CURRENT SMOKER',\n",
       " 'CURRENT SMOKER',\n",
       " 'CURRENT SMOKER',\n",
       " 'CURRENT SMOKER',\n",
       " 'CURRENT SMOKER',\n",
       " 'CURRENT SMOKER',\n",
       " 'CURRENT SMOKER',\n",
       " 'CURRENT SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'PAST SMOKER',\n",
       " 'PAST SMOKER',\n",
       " 'PAST SMOKER',\n",
       " 'PAST SMOKER',\n",
       " 'PAST SMOKER',\n",
       " 'PAST SMOKER',\n",
       " 'PAST SMOKER',\n",
       " 'PAST SMOKER',\n",
       " 'PAST SMOKER',\n",
       " 'PAST SMOKER',\n",
       " 'PAST SMOKER',\n",
       " 'PAST SMOKER',\n",
       " 'PAST SMOKER',\n",
       " 'PAST SMOKER',\n",
       " 'PAST SMOKER',\n",
       " 'PAST SMOKER',\n",
       " 'PAST SMOKER',\n",
       " 'PAST SMOKER',\n",
       " 'PAST SMOKER',\n",
       " 'PAST SMOKER',\n",
       " 'PAST SMOKER',\n",
       " 'PAST SMOKER',\n",
       " 'PAST SMOKER',\n",
       " 'PAST SMOKER',\n",
       " 'PAST SMOKER',\n",
       " 'SMOKER',\n",
       " 'SMOKER',\n",
       " 'SMOKER',\n",
       " 'SMOKER',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'CURRENT SMOKER',\n",
       " 'CURRENT SMOKER',\n",
       " 'CURRENT SMOKER',\n",
       " 'CURRENT SMOKER',\n",
       " 'SMOKER',\n",
       " 'SMOKER',\n",
       " 'SMOKER',\n",
       " 'UNKNOWN',\n",
       " 'CURRENT SMOKER',\n",
       " 'CURRENT SMOKER',\n",
       " 'CURRENT SMOKER',\n",
       " 'CURRENT SMOKER',\n",
       " 'CURRENT SMOKER',\n",
       " 'CURRENT SMOKER',\n",
       " 'CURRENT SMOKER',\n",
       " 'CURRENT SMOKER',\n",
       " 'CURRENT SMOKER',\n",
       " 'CURRENT SMOKER',\n",
       " 'CURRENT SMOKER',\n",
       " 'CURRENT SMOKER',\n",
       " 'CURRENT SMOKER',\n",
       " 'CURRENT SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'NON-SMOKER',\n",
       " 'PAST SMOKER',\n",
       " 'PAST SMOKER',\n",
       " 'PAST SMOKER',\n",
       " 'PAST SMOKER',\n",
       " 'PAST SMOKER',\n",
       " 'PAST SMOKER',\n",
       " 'PAST SMOKER',\n",
       " 'PAST SMOKER',\n",
       " 'PAST SMOKER',\n",
       " 'PAST SMOKER',\n",
       " 'PAST SMOKER',\n",
       " 'SMOKER',\n",
       " 'SMOKER',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN',\n",
       " 'UNKNOWN']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    " \n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "print(device)\n",
    " \n",
    " \n",
    "class CustomTextDataset(Dataset):\n",
    "    def __init__(self, text, labels):\n",
    "        self.labels = labels\n",
    "        self.text = text\n",
    "        \n",
    "    def __len__(self):\n",
    "            return len(self.labels)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "            label = self.labels[idx]\n",
    "            text = self.text[idx]\n",
    "            sample = {\"Text\": text, \"Class\": label}\n",
    "            return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "text = ['Happy', 'Amazing', 'Sad', 'Unhapy', 'Glum']\n",
    "labels = ['Positive', 'Positive', 'Negative', 'Negative', 'Negative']\n",
    "\n",
    "text_labels_df = pd.DataFrame({'Text': text, 'Labels': labels})\n",
    "\n",
    "TD = CustomTextDataset(text_labels_df['Text'],\n",
    "                       text_labels_df['Labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First iteration of data set:  {'Text': 'Happy', 'Class': 'Positive'} \n",
      "\n",
      "Length of data set:  5 \n",
      "\n",
      "Entire data set:  [{'Text': ['Happy'], 'Class': ['Positive']}, {'Text': ['Amazing'], 'Class': ['Positive']}, {'Text': ['Sad'], 'Class': ['Negative']}, {'Text': ['Unhapy'], 'Class': ['Negative']}, {'Text': ['Glum'], 'Class': ['Negative']}] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display text and label.\n",
    "print('\\nFirst iteration of data set: ', next(iter(TD)), '\\n')\n",
    "# Print how many items are in the data set\n",
    "print('Length of data set: ', len(TD), '\\n')\n",
    "# Print entire data set\n",
    "print('Entire data set: ', list(DataLoader(TD)), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h40NMlRG5qWE"
   },
   "source": [
    "# BERT\n",
    "OpenPrompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "rHra-taOa7_R"
   },
   "outputs": [],
   "source": [
    "import openprompt.plms as plms\n",
    "from openprompt.plms.mlm import MLMTokenizerWrapper\n",
    "from transformers import BertConfig, BertForMaskedLM, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "OZWrokM5cF8I"
   },
   "outputs": [],
   "source": [
    "plms._MODEL_CLASSES['bert'] = plms.ModelClass(**{\n",
    "    'config': BertConfig,\n",
    "    'tokenizer': BertTokenizer,\n",
    "    'model':BertForMaskedLM,\n",
    "    'wrapper': MLMTokenizerWrapper,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "gsxMMn8pdQx2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bert': ModelClass(config=<class 'transformers.models.bert.configuration_bert.BertConfig'>, tokenizer=<class 'transformers.models.bert.tokenization_bert.BertTokenizer'>, model=<class 'transformers.models.bert.modeling_bert.BertForMaskedLM'>, wrapper=<class 'openprompt.plms.mlm.MLMTokenizerWrapper'>),\n",
       " 'roberta': ModelClass(config=<class 'transformers.models.roberta.configuration_roberta.RobertaConfig'>, tokenizer=<class 'transformers.models.roberta.tokenization_roberta.RobertaTokenizer'>, model=<class 'transformers.models.roberta.modeling_roberta.RobertaForMaskedLM'>, wrapper=<class 'openprompt.plms.mlm.MLMTokenizerWrapper'>),\n",
       " 'albert': ModelClass(config=<class 'transformers.models.albert.configuration_albert.AlbertConfig'>, tokenizer=<class 'transformers.models.albert.tokenization_albert.AlbertTokenizer'>, model=<class 'transformers.models.albert.modeling_albert.AlbertForMaskedLM'>, wrapper=<class 'openprompt.plms.mlm.MLMTokenizerWrapper'>),\n",
       " 'gpt': ModelClass(config=<class 'transformers.models.openai.configuration_openai.OpenAIGPTConfig'>, tokenizer=<class 'transformers.models.openai.tokenization_openai.OpenAIGPTTokenizer'>, model=<class 'transformers.models.openai.modeling_openai.OpenAIGPTLMHeadModel'>, wrapper=<class 'openprompt.plms.lm.LMTokenizerWrapper'>),\n",
       " 'gpt2': ModelClass(config=<class 'transformers.models.gpt2.configuration_gpt2.GPT2Config'>, tokenizer=<class 'transformers.models.gpt2.tokenization_gpt2.GPT2Tokenizer'>, model=<class 'transformers.models.gpt2.modeling_gpt2.GPT2LMHeadModel'>, wrapper=<class 'openprompt.plms.lm.LMTokenizerWrapper'>),\n",
       " 't5': ModelClass(config=<class 'transformers.models.t5.configuration_t5.T5Config'>, tokenizer=<class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>, model=<class 'transformers.models.t5.modeling_t5.T5ForConditionalGeneration'>, wrapper=<class 'openprompt.plms.seq2seq.T5TokenizerWrapper'>),\n",
       " 't5-lm': ModelClass(config=<class 'transformers.models.t5.configuration_t5.T5Config'>, tokenizer=<class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>, model=<class 'transformers.models.t5.modeling_t5.T5ForConditionalGeneration'>, wrapper=<class 'openprompt.plms.seq2seq.T5LMTokenizerWrapper'>)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plms._MODEL_CLASSES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lqqf6NKRKVgI"
   },
   "source": [
    "# Step 1: Define a task\n",
    "|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "YnhS5PiJJuPM"
   },
   "outputs": [],
   "source": [
    "from openprompt.data_utils import InputExample\n",
    "classes = [ \n",
    "    \"Smoking\",\n",
    "    \"not Smoking\"\n",
    "]\n",
    "\n",
    "dataset = [ \n",
    "      InputExample(\n",
    "        guid = 0,\n",
    "        text_a = \"\"\" smoking causes cancer\n",
    "        \"\"\", #smoking\n",
    "    ),\n",
    "    InputExample(\n",
    "        guid = 1,\n",
    "        text_a = \"\"\"\"This person doesnt smoke\"\"\", #obsese\n",
    "    ),\n",
    "#     InputExample(\n",
    "#         guid = 2,\n",
    "#         text_a = \"When your brain is damaged, it can affect many different things, including your memory, your sensation, and even your personality. Brain disorders include any conditions or disabilities that affect your brain.\", #brain\n",
    "#     ),\n",
    "#     InputExample(\n",
    "#         guid = 3,\n",
    "#         text_a = \"Symptoms may appear 2-14 days after exposure to the virus\", #virus\n",
    "#     ),\n",
    "        InputExample(\n",
    "        guid = 4,\n",
    "        text_a = \"\"\"The patient is healthy and is having a balanced diet.\"\"\", #healthy\n",
    "    ),\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DymjAiXFKYw7"
   },
   "source": [
    "# Step 2: Define a Pre-trained Language Models (PLMs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "rFp3ya01J3nb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from openprompt.plms import load_plm\n",
    "# plm, tokenizer, model_config, WrapperClass = load_plm(\"bert\", \"bert-base-uncased\")\n",
    "plm, tokenizer, model_config, WrapperClass = load_plm(\"bert\", \"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "# plm, tokenizer, model_config, WrapperClass = load_plm(\"bert\", \"mrm8488/bioclinicalBERT-finetuned-covid-papers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "bM7D10XJg49q"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'think', 'this', 'drug', 'is', 'not', 'a', 'solution']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(\"I think this drug is not a solution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zsI0hUZyKe4A"
   },
   "source": [
    "# Step 3: Define a Template.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "HG7p1ETaKg4O"
   },
   "outputs": [],
   "source": [
    "from openprompt.prompts import ManualTemplate\n",
    "from openprompt.prompts import PtuningTemplate\n",
    "# template_text = '{\"placeholder\":\"text_a\"}: This effects {\"mask\"}'\n",
    "template_text= 'A {\"mask\"} disorder :  {\"placeholder\": \"text_a\"}'\n",
    "\n",
    "# promptTemplate = ManualTemplate(\n",
    "#     text = template_text,\n",
    "#     tokenizer = tokenizer,\n",
    "# )\n",
    "\n",
    "promptTemplate = PtuningTemplate(model = plm, \n",
    "                                 tokenizer = tokenizer, \n",
    "                                 text = template_text, \n",
    "                                 prompt_encoder_type = 'mlm'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hthNbpJCKh9R"
   },
   "source": [
    "# Step 4: Define a Verbalizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "QALc5AqJKl6w"
   },
   "outputs": [],
   "source": [
    "from openprompt.prompts import ManualVerbalizer\n",
    "promptVerbalizer = ManualVerbalizer(\n",
    "    classes = classes,\n",
    "    label_words = {\n",
    "        \"Smoking\": [\"smoking\", \"tobacco\", \"cigarette\"],\n",
    "        \"not Smoking\": [\"healthy\"] #\"healthy\", \n",
    "    },\n",
    "    tokenizer = tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WD8leL4PKpNM"
   },
   "source": [
    "# Step 5: Combine them into a PromptModel\n",
    "Given the task, now we have a PLM, a Template and a Verbalizer,  combine them into a PromptModel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "U-qTGso-Kqez"
   },
   "outputs": [],
   "source": [
    "from openprompt import PromptForClassification\n",
    "promptModel = PromptForClassification(\n",
    "    template = promptTemplate,\n",
    "    plm = plm,\n",
    "    verbalizer = promptVerbalizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4E7vuggeKuCI"
   },
   "source": [
    "# Step 6: Define a DataLoader\n",
    "A PromptDataLoader is basically a prompt version of pytorch Dataloader, which also includes a Tokenizer, a Template and a TokenizerWrapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "AkrXsdLgKwh7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 3it [00:00, 928.42it/s]\n"
     ]
    }
   ],
   "source": [
    "from openprompt import PromptDataLoader\n",
    "data_loader = PromptDataLoader(\n",
    "    dataset = dataset,\n",
    "    tokenizer = tokenizer, \n",
    "    template = promptTemplate, \n",
    "    tokenizer_wrapper_class=WrapperClass,\n",
    "    max_seq_length=256, decoder_max_length=3, \n",
    "    batch_size=1,shuffle=False, teacher_forcing=False, predict_eos_token=False,\n",
    "    truncate_method=\"head\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rCQSvF5HK0Z3"
   },
   "source": [
    "# Step 7: Train and inference\n",
    "Done! We can conduct training and inference the same as other processes in Pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "YT4WwqpYK1Z0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.0085, -6.5984]])\n",
      "Smoking\n",
      "tensor([[-2.7888, -8.5340]])\n",
      "Smoking\n",
      "tensor([[-6.2428, -0.0253]])\n",
      "not Smoking\n"
     ]
    }
   ],
   "source": [
    "# making zero-shot inference using pretrained MLM with prompt\n",
    "import torch\n",
    "promptModel.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        logits = promptModel(batch)\n",
    "        print(logits)\n",
    "        preds = torch.argmax(logits, dim = -1)\n",
    "        \n",
    "        print(classes[preds])\n",
    "# predictions would be 1, 0 for classes 'positive', 'negative'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RsY1V4xFQvIw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Openprompt-health example working.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
